{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc376a5",
   "metadata": {},
   "source": [
    "### Date updated\n",
    "2024-01-16\n",
    "\n",
    "### Authors\n",
    "Reshama S\n",
    "\n",
    "### Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50594098-3fe6-422c-b073-08fd8e7b8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2362e9a-26c5-42af-8c90-213d3295c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metric (from Hugging Face)\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad0fee-24da-4fcd-b9b8-2497cb9e18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"My name is Mrs Reshama\"]\n",
    "references = [\"My name is Rachel\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6921eff-3b50-46ec-ad7f-402bf52d7fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75699058",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1_sladjana = (\"\"\"Well, we went to Italy. I enjoyed Italy, enjoyed the food. \\\n",
    "I enjoyed the wine and the women are fantastic. Um its not the safest place in the world but you kind of live with, \\\n",
    "you kind you live with. You know you're supposed to lock your house and close your windows and all that staff. \\\n",
    "Okay. And but everything was fine I mean. No, I lived there. Stayed there for about three years. Naples. \\\n",
    "Lovely place. But like I said its not, its not the safest place to live. \\\n",
    "I spoke a little bit, yeah, a little bit. Yes I did. I worked at the gym. \\\n",
    "She yeah she was uh, uh she ran a tourist place, you know where people want to take a trip. \\\n",
    "She had a lot of people to work for her but people want to take a trip or whatever and she set it up.\"\"\")\n",
    "    \n",
    "print(output1_sladjana)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1eeef-d74f-43c3-b4a3-1687515e7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2_whisper = (\"\"\"While we went to Italy, I enjoyed Italy, enjoyed the food. \\\n",
    "I enjoyed the wine and the women are fantastic. It's not the safest place in the world, \\\n",
    "but you kind of live with it. You live with it. You know, you're supposed to lock your \\\n",
    "house and close your windows and all that stuff. Okay. But everything was fine. No, I lived there. \\\n",
    "Stayed there for about three years. Naples. Lovely place But like I said, it's not the safest place to live. \\\n",
    "I spoke a little bit. Yes, I did. I worked at the adagem. She ran a tourist place. People want to take a trip. \\\n",
    "She had a lot of people who worked for her. She wanted to take a trip or whatever. She said it out. I'll need it.\"\"\")\n",
    "\n",
    "print(output2_whisper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7dfeef-2dda-41ca-aba1-8dc6eaed82ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a0267-353a-4e39-af0f-100d94c58a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output3_assemblyai = (\"\"\"Well, we went to Italy. I enjoyed Italy. Enjoyed the food. \n",
    "I enjoyed the wine. And the women are fantastic. \n",
    "It's not the safest place in the world. You kind of live with. You kind of. You live with it. \n",
    "You know, you're supposed to lock your house and close your windows and all that stuff, but everything was fine.\n",
    "No, I lived there.\n",
    "Stayed there for about three years. What part? Naples. \n",
    "Naples. Lovely place\n",
    "but like I said, it's not the safest place to live. But did.\n",
    "I spoke a little bit, yeah, a little bit.\n",
    "Yes, I did. I worked at a gym.\n",
    "Her job, right? Yeah, she was a. She ran a tourist place where people want to take a a trip. \n",
    "She had a lot of people work for her, but people want to take a trip or whatever but people want to take a trip or whatever. Then she'd set it.\n",
    "\"\"\")\n",
    "\n",
    "print(output3_assemblyai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ca827-8f06-45d3-b4e0-f4cb65a1c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "# load the metric (from Hugging Face)\n",
    "score = evaluate.load('rouge')\n",
    "score = evaluate.load(\"accuracy\")\n",
    "\n",
    "predictions = output2_whisper\n",
    "references = output1_sladjana\n",
    "results = score.compute(predictions=[predictions],\n",
    "                         references=[references])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62347867-095f-4324-b947-762ae1d12b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = output3_assemblyai\n",
    "references = output1_sladjana\n",
    "results = rouge.compute(predictions=[predictions],\n",
    "                         references=[references])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c12350-6989-424a-a9cf-2a95f46f7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = output3_assemblyai\n",
    "references = output2_whisper\n",
    "results = rouge.compute(predictions=[predictions],\n",
    "                         references=[references])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68965c-c628-4da0-8966-2246c030dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test example\n",
    "from nltk import agreement\n",
    "rater1 = [1,1,1]\n",
    "rater2 = [1,1,0]\n",
    "rater3 = [0,1,1]\n",
    "\n",
    "taskdata=[[0,str(i),str(rater1[i])] for i in range(0,len(rater1))]+[[1,str(i),str(rater2[i])] for i in range(0,len(rater2))]+[[2,str(i),str(rater3[i])] for i in range(0,len(rater3))]\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "print(\"alpha \" +str(ratingtask.alpha()))\n",
    "print(\"scotts \" + str(ratingtask.pi()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23cbba-2569-4878-b913-6f74df8481b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rater1 = [output1_sladjana]\n",
    "rater2 = [output2_whisper]\n",
    "rater3 = [output3_assemblyai]\n",
    "\n",
    "taskdata=[[0,str(i),str(rater1[i])] for i in range(0,len(rater1))]+[[1,str(i),str(rater2[i])] for i in range(0,len(rater2))]+[[2,str(i),str(rater3[i])] for i in range(0,len(rater3))]\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "print(\"alpha \" +str(ratingtask.alpha()))\n",
    "print(\"scotts \" + str(ratingtask.pi()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932551b-71fb-4413-aab5-fa76e7379998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4708721-53c4-484f-9d60-d551ef8abbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "first_sentence = \"I see three people who look like they are having a picnic.\"\n",
    "second_sentence = \"I see a dozen people who look like they are walking to the movies.\"\n",
    "\n",
    "levenshtein_distance = distance(first_sentence, second_sentence)\n",
    "\n",
    "print(f\"Levenshtein distance: {levenshtein_distance}\")\n",
    "\n",
    "# Calculate normalized distance (between 0 and 1)\n",
    "sentence_length = max(len(first_sentence), len(second_sentence))\n",
    "normalized_distance = levenshtein_distance / sentence_length\n",
    "\n",
    "print(f\"Normalized Levenshtein distance: {normalized_distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d54842-6d21-4a4c-b2ec-ef92a4183bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein_distance = distance(output1_sladjana, output2_whisper)\n",
    "\n",
    "print(f\"Levenshtein distance: {levenshtein_distance}\")\n",
    "\n",
    "# Calculate normalized distance (between 0 and 1)\n",
    "sentence_length = max(len(first_sentence), len(second_sentence))\n",
    "normalized_distance = levenshtein_distance / sentence_length\n",
    "\n",
    "print(f\"Normalized Levenshtein distance: {normalized_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29427dad-3e9f-4094-8f45-0b51a1295a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800628db-440a-4d08-92c3-e8784183ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8612ea-6018-4a89-9631-d2031d8446ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [['this', 'is', 'a', 'test'], ['this', 'is', 'another', 'test']]  # Multiple references\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "\n",
    "score = sentence_bleu(references, candidate)\n",
    "print(score)  # Output: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491f6d6-442b-45d2-94e1-bbe1156ca6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "#references = [['this', 'is', 'a', 'good', 'translation'], ['another', 'good', 'translation', 'example']]\n",
    "references = [['this', 'is', 'a', 'good', 'translation']]\n",
    "\n",
    "candidate = ['this', 'is', 'a', 'good', 'example']\n",
    "\n",
    "# Emphasize unigrams and bigrams, while slightly considering trigrams:\n",
    "weights = (0.5, 0.4, 0.2, 0)  # Weights for 1-gram, 2-gram, 3-gram, 4-gram\n",
    "#weights = (0.1, 0.1, 0.1, 0)\n",
    "weights = (0.1, 0.2, 0.05, 0)\n",
    "weights = (0.5, 0, 0, 0)\n",
    "weights = (1.0, 0, 0, 0) # this gives 80% score, when only checking words\n",
    "weights = (0.6, 0.3, 0.1, 0)\n",
    "\n",
    "score = sentence_bleu(references, candidate, weights=weights)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49dc8c-5128-434e-9312-5c840a439314",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output1_sladjana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c80b53-cfff-44a1-8886-9852744f6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1_slad_tokens = nltk.word_tokenize(output1_sladjana)\n",
    "print(out1_slad_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba046e-2f9c-4c1f-85e6-ee08a7a9649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2_whis_tokens = nltk.word_tokenize(output2_whisper)\n",
    "print(out2_whis_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5abd324-47c2-468f-9d1a-202141dae98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (1.0, 0, 0, 0) # this gives 80% score, when only checking words\n",
    "weights = (0.5, 0.4, 0.1, 0)\n",
    "\n",
    "score = sentence_bleu(out1_slad_tokens, out2_whis_tokens, weights=weights)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4650bac-f56e-432c-bb70-88f69474d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "sentence1 = \"I see three people who look like they are having a picnic.\"\n",
    "sentence2 = \"I see a dozen people who seem to be walking to the movies.\"\n",
    "\n",
    "disagreement = distance(sentence1, sentence2)\n",
    "\n",
    "print(f\"Levenshtein disagreement: {disagreement}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b1b54e-d403-4e45-bb18-fdb93863619b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'jaccard_similarity' from 'nltk.metrics' (/Users/reshamas/opt/anaconda3/envs/nlp-project1/lib/python3.11/site-packages/nltk/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jaccard_similarity\n\u001b[1;32m      3\u001b[0m sentence1_tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(sentence1)\n\u001b[1;32m      4\u001b[0m sentence2_tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(sentence2)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'jaccard_similarity' from 'nltk.metrics' (/Users/reshamas/opt/anaconda3/envs/nlp-project1/lib/python3.11/site-packages/nltk/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import jaccard_similarity\n",
    "\n",
    "sentence1_tokens = nltk.word_tokenize(sentence1)\n",
    "sentence2_tokens = nltk.word_tokenize(sentence2)\n",
    "\n",
    "disagreement_percent = (1 - jaccard_similarity(sentence1_tokens, sentence2_tokens)) * 100\n",
    "\n",
    "print(f\"Percent rater disagreement (Jaccard): {disagreement_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ddf07-0b93-457d-8aa7-e83ea1794889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall nltk\n",
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425edfa-85d1-48c0-a575-ed81389a86e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31495466-acbe-4ee7-b6ba-18a781f61247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
