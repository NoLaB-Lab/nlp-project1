{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc376a5",
   "metadata": {},
   "source": [
    "### Info\n",
    "- Updated: 2024-05-15\n",
    "- Author: Reshama S\n",
    "- Location: https://github.com/NoLaB-Lab/nlp-project1\n",
    "\n",
    "### Description\n",
    "- Evalute human vs ai VS ASSEMBLY AI transcripts\n",
    "\n",
    "### ROUGE score\n",
    "- A ROUGE score close to zero indicates poor similarity between candidate and references. \n",
    "- A ROUGE score close to one indicates strong similarity between candidate and references. \n",
    "- If candidate is identical to one of the reference documents, then score is 1.\n",
    "\n",
    "### Levenshtein score\n",
    "https://rapidfuzz.github.io/Levenshtein/levenshtein.html#distance\n",
    "\n",
    "#### Assembly AI\n",
    "https://www.assemblyai.com/playground/playground/transcript/14cf0430-9281-4ea2-9569-019be2d715af\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4e6991-bede-48bb-bccf-a99321aa4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import pprint\n",
    "from Levenshtein import distance\n",
    "from Levenshtein import ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0bd6c5-7ad2-4571-8286-fe8201ddf62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_human = \"../data/transcripts-clinician/\"\n",
    "dir_ai = \"../data/transcripts-whisper/\"\n",
    "\n",
    "dict_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c74dec-5f5c-4267-a83f-f7dbc99d7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: https://towardsdatascience.com/side-by-side-comparison-of-strings-in-python-b9491ac858\n",
    "\n",
    "import difflib\n",
    "import re\n",
    "\n",
    "def tokenize(s):\n",
    "    return re.split('\\s+', s)\n",
    "def untokenize(ts):\n",
    "    return ' '.join(ts)\n",
    "        \n",
    "def equalize(s1, s2):\n",
    "    l1 = tokenize(s1)\n",
    "    l2 = tokenize(s2)\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    prev = difflib.Match(0,0,0)\n",
    "    for match in difflib.SequenceMatcher(a=l1, b=l2).get_matching_blocks():\n",
    "        if (prev.a + prev.size != match.a):\n",
    "            for i in range(prev.a + prev.size, match.a):\n",
    "                res2 += ['_' * len(l1[i])]\n",
    "            res1 += l1[prev.a + prev.size:match.a]\n",
    "        if (prev.b + prev.size != match.b):\n",
    "            for i in range(prev.b + prev.size, match.b):\n",
    "                res1 += ['_' * len(l2[i])]\n",
    "            res2 += l2[prev.b + prev.size:match.b]\n",
    "        res1 += l1[match.a:match.a+match.size]\n",
    "        res2 += l2[match.b:match.b+match.size]\n",
    "        prev = match\n",
    "    return untokenize(res1), untokenize(res2)\n",
    "\n",
    "def insert_newlines(string, every=64, window=10):\n",
    "    result = []\n",
    "    from_string = string\n",
    "    while len(from_string) > 0:\n",
    "        cut_off = every\n",
    "        if len(from_string) > every:\n",
    "            while (from_string[cut_off-1] != ' ') and (cut_off > (every-window)):\n",
    "                cut_off -= 1\n",
    "        else:\n",
    "            cut_off = len(from_string)\n",
    "        part = from_string[:cut_off]\n",
    "        result += [part]\n",
    "        from_string = from_string[cut_off:]\n",
    "    return result\n",
    "\n",
    "def show_comparison(s1, s2, width=40, margin=10, sidebyside=True, compact=False):\n",
    "    s1, s2 = equalize(s1,s2)\n",
    "\n",
    "    if sidebyside:\n",
    "        s1 = insert_newlines(s1, width, margin)\n",
    "        s2 = insert_newlines(s2, width, margin)\n",
    "        if compact:\n",
    "            for i in range(0, len(s1)):\n",
    "                lft = re.sub(' +', ' ', s1[i].replace('_', '')).ljust(width)\n",
    "                rgt = re.sub(' +', ' ', s2[i].replace('_', '')).ljust(width) \n",
    "                print(lft + ' | ' + rgt + ' | ')        \n",
    "        else:\n",
    "            for i in range(0, len(s1)):\n",
    "                lft = s1[i].ljust(width)\n",
    "                rgt = s2[i].ljust(width)\n",
    "                print(lft + ' | ' + rgt + ' | ')\n",
    "    else:\n",
    "        print(s1)\n",
    "        print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969abd45-a610-4a31-af7f-c55294e08a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtext(patientnum, filename1, filename2):\n",
    "    #print(filename)\n",
    "    filename=patientnum\n",
    "    # Added 2024-05-15\n",
    "    dir_human = \"../data/test-data/\"\n",
    "    dir_ai = \"../data/test-data/\"\n",
    "    \n",
    "    file = open(dir_human + filename1 + \".txt\", \"r\")\n",
    "    content_human = file.read()\n",
    "    file.close()\n",
    "    #print(content_human)\n",
    "    #print(\"-\" * 50)\n",
    "    \n",
    "    file_ai = open(dir_ai + filename2 + \".txt\", \"r\")\n",
    "    content_ai = file_ai.read()\n",
    "    file_ai.close()\n",
    "    #print(content_ai)\n",
    "    #print(\"-\" * 50)\n",
    "    return filename, content_human, content_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49e549-68c6-4bc0-bfbc-971c83ba171d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0180da8d-c06b-4ce1-a997-65d756790bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaltext(filename, content_human, content_ai):\n",
    "    #print(filename)\n",
    "    # load the metric (from Hugging Face)\n",
    "    score = evaluate.load('rouge')\n",
    "    #score = evaluate.load(\"accuracy\") # this gives error\n",
    "\n",
    "    results = score.compute(predictions=[content_ai],\n",
    "                         references=[content_human])\n",
    "    print(results)\n",
    "    dict_scores[filename] = results\n",
    "\n",
    "    disagreement = distance(content_human, content_ai)\n",
    "    print(f\"Levenshtein disagreement: {disagreement}\")\n",
    "    \n",
    "    ratiov = ratio(content_human, content_ai)\n",
    "    print(f\"Levensshtein ratio: {ratiov}\")\n",
    "\n",
    "    # Calculate normalized distance (between 0 and 1)\n",
    "    levenshtein_distance = distance(content_human, content_ai)\n",
    "    print(f\"Levenshtein distance: {levenshtein_distance}\")\n",
    "    sentence_length = max(len(content_human), len(content_ai))\n",
    "    normalized_distance = levenshtein_distance / sentence_length\n",
    "\n",
    "    print(f\"Normalized Levenshtein distance: {normalized_distance}\")\n",
    "\n",
    "    print('-' * 52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55bdf90-9a61-4bc7-9bbc-edb666ae24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comptext(filename, content_human, content_ai):\n",
    "    show_comparison(content_human, content_ai, width=50, sidebyside=True, compact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c678355-a80a-4d58-81e5-15738d71c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runanalysis(patientnum, filename1, filename2, printcomp):\n",
    "    print(patientnum)\n",
    "    filename, content_human, content_ai = readtext(patientnum, filename1, filename2)\n",
    "    evaltext(filename, content_human, content_ai)\n",
    "    if printcomp == 1:\n",
    "        comptext(filename, content_human, content_ai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb0146-0c1f-4198-9be0-f9eb20e300fc",
   "metadata": {},
   "source": [
    "## Compare human vs Assembly AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7dd6ac-51ba-442e-8f63-6a91c49fa94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_IMG_2863\n",
      "{'rouge1': 0.7891156462585033, 'rouge2': 0.6758620689655173, 'rougeL': 0.7891156462585033, 'rougeLsum': 0.7891156462585033}\n",
      "Levenshtein disagreement: 103\n",
      "Levensshtein ratio: 0.8237037037037037\n",
      "Levenshtein distance: 103\n",
      "Normalized Levenshtein distance: 0.28065395095367845\n",
      "----------------------------------------------------\n",
      "Yeah _____ I have fairly ___ _ _______ ______      | ____ Yeah, I ____ ______ had a pretty. Fairly      | \n",
      "good, you know, no issues that I can really        | good, you know, no issues that I can really        | \n",
      "remeber but _________ ___ I do remember falling    | _______ ___ remember. But I do remember falling    | \n",
      "out of a tree. Thank god ___ it wasnt ______ too   | out of a tree. Thank ___ God it _____ wasn't too   | \n",
      "high Reaching _____ ___ _____ ________ for the     | ____ ________ high, you know, reaching for the     | \n",
      "next one and the next one andall ____ ___ ____     | next one and the next ___ ______ one, and then     | \n",
      "___ of a sudden ______ ________ ___ you don't get  | all of a sudden you're reaching and you don't get  | \n",
      "it ___ and \"pew bam\" ___ ____ It wasn't horrible   | __ it, and ____ ____ you bam. It wasn't ________   | \n",
      "_________ but it hurt ____ ______ No, I _______    | horrible, but __ ____ it's scary. No, I didn't.    | \n",
      "___ ____ never had a broken bone Thank god  _____  | No. I've never had a broken ____ _____ ___  bone.  | \n"
     ]
    }
   ],
   "source": [
    "# lowest score\n",
    "runanalysis(\"SS_IMG_2863\", \"SS_IMG_2863_human_pt\", \"SS_IMG_2863_assemblyai_pt\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a4db6c9-02f5-47f9-9047-bde949f20c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_IMG_2863\n",
      "{'rouge1': 0.8079470198675496, 'rouge2': 0.697986577181208, 'rougeL': 0.8079470198675496, 'rougeLsum': 0.8079470198675496}\n",
      "Levenshtein disagreement: 102\n",
      "Levensshtein ratio: 0.833810888252149\n",
      "Levenshtein distance: 102\n",
      "Normalized Levenshtein distance: 0.26153846153846155\n",
      "----------------------------------------------------\n",
      "Yeah _____ I have ___ _ ______ fairly good, you    | ____ Yeah. I ____ had a pretty fairly good, you    | \n",
      "know, no issues that I can really remeber          | know, no issues that I can really _______          | \n",
      "_________ but I do remember falling out of a       | remember, but I do remember falling out of a       | \n",
      "tree. Thank god ___ it wasnt ______ too high       | tree. Thank ___ God it _____ wasn't too ____       | \n",
      "Reaching _____ ___ _____ ________ for the next     | ________ high. You know, reaching for the next     | \n",
      "one and the next one andall ____ ___ ____ ___ of   | one and the next ___ ______ one, and then all of   | \n",
      "a sudden ______ ________ ___ you don't get it ___  | a sudden you're reaching and you don't get __ it,  | \n",
      "and \"pew bam\" ____ ____ It wasn't horrible         | and ____ ____ you, bam. It wasn't ________         | \n",
      "_________ but it hurt _____ __ _____ _____ No, I   | horrible, but it ____ hurt. It hurt, yeah. No, I   | \n",
      "_______ ___ ____ never had a broken bone _____     | didn't. No, I've never had a broken ____ bone.     | \n",
      "Thank god  ____                                    | Thank ___  God.                                    | \n"
     ]
    }
   ],
   "source": [
    "# lowest score\n",
    "runanalysis(\"SS_IMG_2863\", \"SS_IMG_2863_human_pt\", \"SS_IMG_2863_whisperai_pt\", printcomp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ee295-9a1f-40d4-a3c3-a22a620521bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637ad70-fa59-4b01-b43b-6cf7cbdc2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c5711-83ca-4ac7-a532-078dd32dc2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf979da-a5d3-4d51-bc68-3d4fd238a374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e8cd4-16e8-4dce-baca-94facd60031d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10020c94-724b-4d32-a2a1-430f8056a9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bdb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480e346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425edfa-85d1-48c0-a575-ed81389a86e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31495466-acbe-4ee7-b6ba-18a781f61247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
